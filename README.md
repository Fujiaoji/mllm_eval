# Llama
- Notes: I use the llama vision model, so maybe the text model is a little different
- conda env, install `hugging face`, access `meta llama`, find the appropriate model
- choose the model id and save to the appropriate path
- put the prompt into the `jp_prompt.txt`, put the input into the `jp.txt` or other format
- save the output into file
- `python connect_llama_jp.py` to get the response