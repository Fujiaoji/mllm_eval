# Llama
- conda env, install `hugging face`, access `meta llama`, find the appropriate model
- choose the model id and save to the appropriate path
- put the prompt into the `jp_prompt.txt`, put the input into the `jp.txt` or other format
- save the output into file
- `python connect_llama_jp.py` to get the response